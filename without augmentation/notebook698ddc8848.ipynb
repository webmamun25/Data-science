{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\ndircs=os.listdir('/kaggle/input/fishdataset/combine/FishDisease/')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_directory=[]\ny_directory=[]\nfor directory in dircs:\n    image_paths=os.listdir(f'/kaggle/input/fishdataset/combine/FishDisease/{directory}')\n    for img_name in image_paths:\n        X_directory.append(f'/kaggle/input/fishdataset/combine/FishDisease/{directory}/{img_name}')\n        y_directory.append(directory)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df={\"fishimages\":X_directory,\"fishlabels\":y_directory}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(df)\ndf.style","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf=pd.DataFrame(df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\ndf = df.sample(frac=1).reset_index(drop=True)\nonehot=OneHotEncoder()\nlab=onehot.fit_transform(df['fishlabels'].values.reshape(-1,1)).toarray()\nimages=df['fishimages']\nprint('total labels of images',len(lab))\nprint('total images',len(images))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nimgs=[]\nfor img in images:\n    if img.startswith(\"/kaggle/input/fishdataset/combine/FishDisease/white spot/\"):\n        other_imag = cv2.imread(img)\n\n        other_frame = cv2.resize(other_imag,(224,224))\n        kernel = np.array([[0, -1, 0],\n               [-1, 5,-1],\n               [0, -1, 0]])\n        image_sharp = cv2.filter2D(src=other_frame, ddepth=-1, kernel=kernel)\n        hsv = cv2.cvtColor(image_sharp, cv2.COLOR_BGR2HSV)\n\n        # define range of white color in HSV\n        # change it according to your need !\n        lower_white = np.array([0,0,168], dtype=np.uint8)\n        upper_white = np.array([172,111,255],dtype=np.uint8)\n\n        # Threshold the HSV image to get only white colors\n        mask = cv2.inRange(hsv, lower_white, upper_white)\n        # Bitwise-AND mask and original image\n        res = cv2.bitwise_and(image_sharp,image_sharp, mask= mask)\n        imgs.append(res)\n         \n    elif img.startswith(\"/kaggle/input/fishdataset/combine/FishDisease/red spot/\"):\n        imag = cv2.imread(img)\n\n        frame = cv2.resize(imag,(224,224)) \n\n        kernel = np.array([[0, -1, 0],\n                   [-1, 5,-1],\n                   [0, -1, 0]])\n        image_sharp = cv2.filter2D(src=frame, ddepth=-1, kernel=kernel)\n        hsv = cv2.cvtColor(image_sharp,cv2.COLOR_BGR2HSV)\n\n        lower_red = np.array([0,50,50])\n        upper_red = np.array([10,255,255])\n\n\n        #upper red\n        lower_red2 = np.array([170,50,50])\n        upper_red2 = np.array([180,255,255])\n\n        mask = cv2.inRange(hsv, lower_red, upper_red)\n        res = cv2.bitwise_and(image_sharp,image_sharp, mask= mask)\n\n\n        mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n        res2 = cv2.bitwise_and(image_sharp,image_sharp, mask= mask2)\n\n        red=res+res2\n        imgs.append(red)\n    elif img.startswith(\"/kaggle/input/fishdataset/combine/FishDisease/black spot/\"):\n        other_imag = cv2.imread(img)\n\n        other_frame = cv2.resize(other_imag,(224,224))\n        kernel = np.array([[0, -1, 0],\n               [-1, 5,-1],\n               [0, -1, 0]])\n        image_sharp = cv2.filter2D(src=other_frame, ddepth=-1, kernel=kernel)\n        imagehsv = cv2.cvtColor(image_sharp, cv2.COLOR_BGR2HSV)\n\n\n        lower_black = np.array([0,0,0])\n        upper_black = np.array([179,255,127])\n\n        imagemask = cv2.inRange(imagehsv, lower_black, upper_black)\n        result = cv2.bitwise_not(image_sharp,image_sharp, mask=imagemask)\n\n        imgs.append(result)\n    elif img.startswith(\"/kaggle/input/fishdataset/combine/FishDisease/fresh fish/\"):\n        other_imag = cv2.imread(img)\n\n        other_frame = cv2.resize(other_imag,(224,224))\n        kernel = np.array([[0, -1, 0],\n               [-1, 5,-1],\n               [0, -1, 0]])\n        image_sharp = cv2.filter2D(src=other_frame, ddepth=-1, kernel=kernel)\n\n        imgs.append(image_sharp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_preprocess=np.array(imgs)\ny_preprocess=np.array(lab)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.image as mimg\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (10,7)\nfrom PIL import Image\nfrom scipy import misc\n\nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n\n# DEEP LEARNING IMPORTS\nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Conv2D, Activation, Dropout, Flatten, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_x, test_x, train_y, test_y = train_test_split(X_preprocess, y_preprocess, random_state = 42, \n                                                   test_size=0.30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_norm=train_x/255.0\nX_test_norm=test_x/255.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_single_dim=np.argmax(train_y,axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom keras.models import Sequential\nfrom keras.layers import Dense, BatchNormalization, Dropout\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom math import floor\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom bayes_opt import BayesianOptimization\nfrom sklearn.model_selection import StratifiedKFold\nfrom keras.layers import LeakyReLU\nLeakyReLU = LeakyReLU(alpha=0.1)\nimport warnings\nwarnings.filterwarnings('ignore')\npd.set_option(\"display.max_columns\", None)\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom kerastuner.tuners import RandomSearch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(hp):\n    # create model object\n    model = keras.Sequential([\n    #adding first convolutional layer    \n    keras.layers.Conv2D(\n        #adding filter \n        filters=hp.Int('conv_1_filter', min_value=128, max_value=256, step=32),\n        # adding filter size or kernel size\n        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n        #activation function\n        activation='relu',\n        input_shape=(224,224,3)),\n    # adding second convolutional layer \n    \n    # adding flatten layer    \n    keras.layers.Flatten(),\n    # adding dense layer    \n#     keras.layers.Dense(\n#         units=640,\n#         activation='relu'\n#     ),\n    # output layer    \n    keras.layers.Dense(4, activation='softmax')\n    ])\n    #compilation of model\n    model.compile(optimizer=keras.optimizers.Adam(0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kerastuner import RandomSearch\nfrom keras.callbacks import EarlyStopping\n#creating randomsearch object\ntuner = RandomSearch(build_model,\n                    objective='val_accuracy',\n                    max_trials = 5)\n# search best parameter\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\nmc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\ntuner.search(X_train_norm, train_y, epochs=30,batch_size=20, validation_data=(X_test_norm, test_y),callbacks=[es,mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import keras_tuner as kt\n# class MyHyperModel(kt.HyperModel):\n#     def build(self, hp):\n#         model = keras.Sequential()\n        \n#         model.add(layers.Flatten(input_shape=(224,224,3)))\n#         model.add(\n#             layers.Dense(\n#                 units=1024,\n#                 activation=\"relu\",\n#             )\n#         )\n#         model.add(layers.Dense(4, activation=\"softmax\"))\n#         model.compile(\n#             optimizer=keras.optimizers.Adam(0.001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n#         )\n#         return model\n\n#     def fit(self, hp, model, *args, **kwargs):\n#         return model.fit(\n#             *args,\n#             epochs=hp.Choice(\"epochs\", [30,50]),\n#             batch_size=hp.Choice(\"batch_size\", [32]),\n#             **kwargs,\n#         )\n\n# tuner = kt.RandomSearch(\n#     MyHyperModel(),\n#     objective=\"val_accuracy\",\n#     max_trials=3,\n#     overwrite=True,\n#     directory=\"my_dir\",\n#     project_name=\"tune_hypermodel\",\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def build_model(hp):\n    \n#         model = keras.Sequential()\n#         model.add(layers.Flatten(input_shape=(224,224,3)))\n#         model.add(layers.Dense(units=hp.Int('units', min_value=512, max_value=1024, step=128), activation='relu'))\n        \n#         model.add(layers.Dense(4, activation='softmax'))\n#         model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-3, 1e-4])),\n#             loss = 'categorical_crossentropy', metrics = ['accuracy'])\n#         return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kerastuner import RandomSearch\nfrom keras.callbacks import EarlyStopping\n# creating randomsearch object\n# tuner = RandomSearch(build_model,\n#                     objective='val_accuracy',\n#                     max_trials = 5)\n# search best parameter\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n\ntuner.search(X_train_norm, train_y,batch_size=20,epochs=30 validation_data=(X_test_norm, test_y),callbacks=[es])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.search_space_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tuner.search(X_train_norm, train_y, epochs=30, validation_data=(X_test_norm, test_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tuner.results_summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"###  parameter tuning 70-30\nTrial summary\nHyperparameters:\nunits: 1024\nlearning_rate: 0.001\n\n\n## 8-32-8\nconv_1_filter: 24\nconv_1_kernel: 5\nScore: 0.9060240983963013\n## 32-128-16\nconv_1_filter: 96\nconv_1_kernel: 5\nScore: 0.891566276550293\n## 128-256-32\nHyperparameters:\nconv_1_filter: 192\nconv_1_kernel: 3\nScore: 0.9228915572166443\n\n## Epochs 30-50-16\nepochs: 30\nbatch_size: 16\nScore: 0.7108433842658997\n## Epochs 30-50-32\nepochs: 30\nbatch_size: 32\nScore: 0.6963855624198914\n    \n## Epochs 30-50-20\nepochs: 30\nbatch_size: 20\nScore: 0.7855421900749207\n\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}